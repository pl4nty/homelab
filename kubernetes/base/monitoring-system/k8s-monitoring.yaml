# yaml-language-server: $schema=https://flux-helm-schema.tplant.com.au?values=https://raw.githubusercontent.com/grafana/k8s-monitoring-helm/refs/heads/main/charts/k8s-monitoring/values.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: k8s-monitoring
  namespace: monitoring-system
spec:
  interval: 15m
  chart:
    spec:
      chart: k8s-monitoring
      version: 2.0.5
      sourceRef:
        kind: HelmRepository
        name: grafana
        namespace: flux-system
  maxHistory: 3
  install:
    createNamespace: true
    remediation:
      retries: 3
    crds: CreateReplace
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
    crds: CreateReplace
  uninstall:
    keepHistory: false
  values:
    cluster:
      name: ${CLUSTER_NAME:=bootstrap}
    destinations:
      - name: metrics
        type: prometheus
        url: https://prometheus-prod-09-prod-au-southeast-0.grafana.net/api/prom/push
        auth:
          type: basic
        secret:
          create: false
          name: k8s-monitoring-metrics
          namespace: monitoring-system
        metricProcessingRules: |-
          write_relabel_config {
            source_labels = ["namespace","pod"]
            separator = "@"
            regex = "flux-system@(.+)-.+-.+"
            target_label = "uid"
            replacement = ""
          }
          write_relabel_config {
            source_labels = ["namespace","pod"]
            separator = "@"
            regex = "flux-system@(.+)-.+-.+"
            target_label = "pod"
            replacement = "$1"
          }
      - name: logs
        type: loki
        url: https://logs-prod-004.grafana.net/loki/api/v1/push
        auth:
          type: basic
        secret:
          create: false
          name: k8s-monitoring-logs
          namespace: monitoring-system
      - name: traces
        type: otlp
        protocol: http
        url: https://tempo-prod-03-au-southeast-0.grafana.net/tempo
        auth:
          type: basic
        secret:
          create: false
          name: k8s-monitoring-traces
          namespace: monitoring-system

    clusterMetrics:
      enabled: true
      # TODO enable after cluster consolidation
      # controlPlane:
      #   enabled: true
      # kubeProxy:
      #   enabled: true
      kube-state-metrics:
        metricsTuning:
          excludeMetrics:
            - kube_pod_status_reason
            - kube_replicaset_created
            - kube_replicaset_metadata_generation
            - kube_replicaset_spec_replicas
            - kube_replicaset_status_.*
            - kube_secret_metadata_resource_version
            - kube_pod_container_status_restarts_total
      node-exporter:
        metricsTuning:
          excludeMetrics:
            - node_filesystem_device_error
            - node_filesystem_readonly

      # energy metrics
      # kepler:
      # cost metrics
      # opencost:
    clusterEvents:
      enabled: true
    # journald isn't available on Talos
    # nodeLogs:
    podLogs:
      enabled: true
      gatherMethod: kubernetesApi
    applicationObservability:
      enabled: true
      receivers:
        otlp:
          grpc:
            enabled: true
          http:
            enabled: true
    # eBPF, but we already have OTel
    # autoInstrumentation:
    # just use prom CRDs
    # annotationAutodiscovery:
    prometheusOperatorObjects:
      enabled: true
      crds:
        deploy: true
    # 4GB/day but only 50GB/month limit
    # profiling:
    # likely high metrics
    # integrations:
    selfReporting:
      enabled: false

    alloy-metrics:
      enabled: true
    alloy-singleton:
      enabled: true
    alloy-logs:
      enabled: true
      controller:
        # daemonset isn't necessary without nodeLogs
        type: deployment
    alloy-receiver:
      enabled: true
      controller:
        type: deployment
      alloy:
        extraPorts:
          - name: otlp-grpc
            port: 4317
            targetPort: 4317
            protocol: TCP
          - name: otlp-http
            port: 4318
            targetPort: 4318
            protocol: TCP

    # logs:
    #   extraConfig: |-
    #     loki.source.syslog "syslog_udp" {
    #       listener {
    #         address = "0.0.0.0:514"
    #         protocol = "udp"
    #         labels = { job = "integrations/syslog_exporter" }
    #       }

    #       forward_to = [loki.write.grafana_cloud_loki.receiver]
    #     }
    # grafana-agent-logs:
    #   agent:
    #     extraPorts:
    #       - name: syslog-udp
    #         port: 514
    #         targetPort: 514
    #         protocol: UDP
    # metrics:
    #   kube-state-metrics:
    #     metricsTuning:
    #       excludeMetrics:
    #         - kube_replicaset_status_.*
    #         - kube_replicaset_created
    #         - kube_replicaset_metadata_generation
    #         - kube_replicaset_owner
    #         - kube_replicaset_spec_replicas
    #         - kube_pod_status_reason
    #         - node_namespace_pod_container:container_memory_cache
    #         - node_namespace_pod_container:container_memory_swap
    #         - kube_pod_container_status_restarts_total
    #         - kubelet_cgroup_manager_duration_seconds_bucket
    #         - kubelet_pod_start_duration_seconds_bucket
    #         - container_fs_.*
    #         - cluster:namespace:pod_.*
    #         - container_network_.*
    #   node-exporter:
    #     metricsTuning:
    #       dropMetricsForFilesystem:
    #         - tempfs # default
    #         - tmpfs
