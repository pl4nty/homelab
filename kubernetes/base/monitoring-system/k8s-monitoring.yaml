# yaml-language-server: $schema=https://flux-helm-schema.tplant.com.au?values=https://raw.githubusercontent.com/grafana/k8s-monitoring-helm/refs/heads/main/charts/k8s-monitoring/values.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: k8s-monitoring
  namespace: monitoring-system
spec:
  interval: 15m
  chart:
    spec:
      chart: k8s-monitoring
      version: 2.0.24
      sourceRef:
        kind: HelmRepository
        name: grafana
        namespace: flux-system
  maxHistory: 3
  install:
    createNamespace: true
    remediation:
      retries: 3
    crds: CreateReplace
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
    crds: CreateReplace
  uninstall:
    keepHistory: false
  values:
    cluster:
      name: ${CLUSTER_NAME:=bootstrap}
    destinations:
      - name: metrics
        type: prometheus
        url: https://prometheus-prod-09-prod-au-southeast-0.grafana.net/api/prom/push
        auth:
          type: basic
        secret:
          create: false
          name: k8s-monitoring-metrics
          namespace: monitoring-system
        metricProcessingRules: |-
          write_relabel_config {
            source_labels = ["namespace","pod"]
            separator = "@"
            regex = "flux-system@(.+)-.+-.+"
            target_label = "uid"
            replacement = ""
          }
          write_relabel_config {
            source_labels = ["namespace","pod"]
            separator = "@"
            regex = "flux-system@(.+)-.+-.+"
            target_label = "pod"
            replacement = "$1"
          }
      - name: logs
        type: loki
        url: https://logs-prod-004.grafana.net/loki/api/v1/push
        auth:
          type: basic
        secret:
          create: false
          name: k8s-monitoring-logs
          namespace: monitoring-system
      - name: otlp
        type: otlp
        url: https://otlp-gateway-prod-au-southeast-0.grafana.net/otlp
        protocol: http
        auth:
          type: basic
        secret:
          create: false
          name: k8s-monitoring
          namespace: monitoring-system

    clusterMetrics:
      enabled: true
      # TODO enable after cluster consolidation
      # controlPlane:
      #   enabled: true
      # kubeProxy:
      #   enabled: true
      kube-state-metrics:
        metricsTuning:
          excludeMetrics:
            - kube_pod_status_reason
            - kube_replicaset_created
            - kube_replicaset_metadata_generation
            - kube_replicaset_spec_replicas
            - kube_replicaset_status_.*
            - kube_secret_metadata_resource_version
            - kube_pod_container_status_restarts_total
      node-exporter:
        metricsTuning:
          excludeMetrics:
            - node_filesystem_device_error
            - node_filesystem_readonly

      # energy metrics
      # kepler:
      # cost metrics
      # opencost:
    clusterEvents:
      enabled: true
    # journald isn't available on Talos
    # nodeLogs:
    podLogs:
      enabled: true
      gatherMethod: kubernetesApi
    applicationObservability:
      enabled: true
      receivers:
        otlp:
          grpc:
            enabled: true
          http:
            enabled: true
    # eBPF, but we already have OTel
    # autoInstrumentation:
    # just use prom CRDs
    # annotationAutodiscovery:
    prometheusOperatorObjects:
      enabled: true
      crds:
        deploy: true
    # 4GB/day but only 50GB/month limit
    # profiling:
    # likely high metrics
    # integrations:
    selfReporting:
      enabled: false

    alloy-metrics:
      enabled: true
    alloy-singleton:
      enabled: true
    alloy-logs:
      enabled: true
      controller:
        # daemonset isn't necessary without nodeLogs
        type: deployment
      alloy:
        mounts:
          varlog: false
        extraPorts:
        - name: tcplog
          port: 5044
          targetPort: 5044
          protocol: TCP
      # TODO pending https://github.com/grafana/alloy/pull/2701
        stabilityLevel: experimental
      image:
        tag: v1.7.0-rc.3
      extraConfig: |-
        otelcol.receiver.syslog "syslog" {
          protocol = "rfc3164"
          location = "Australia/Canberra"

          udp {
            listen_address = "0.0.0.0:514"
          }

          output {
            logs = [otelcol.processor.transform.syslog.input]
          }
        }

        otelcol.processor.transform "syslog" {
          error_mode = "silent"

          log_statements {
            context = "log"
            statements = [
              `set(resource.attributes["service.name"], "syslog")`,
            ]
          }

          output {
            logs = [otelcol.exporter.loki.logs.input]
          }
        }

        otelcol.receiver.tcplog "tcplog" {
          listen_address = "0.0.0.0:5044"

          output {
            logs = [otelcol.processor.transform.tcplog.input]
          }
        }

        otelcol.processor.transform "tcplog" {
          error_mode = "silent"

          log_statements {
            context = "log"
            statements = [
              `set(resource.attributes["service.name"], "tcplog")`,
            ]
          }

          output {
            logs = [otelcol.exporter.loki.logs.input]
          }
        }
    alloy-receiver:
      enabled: true
      controller:
        type: deployment
      alloy:
        extraPorts:
          - name: otlp-grpc
            port: 4317
            targetPort: 4317
            protocol: TCP
          - name: otlp-http
            port: 4318
            targetPort: 4318
            protocol: TCP
    # grafana-agent-logs:
    #   agent:
    #     extraPorts:
    #       - name: syslog-udp
    #         port: 514
    #         targetPort: 514
    #         protocol: UDP
    # metrics:
    #   kube-state-metrics:
    #     metricsTuning:
    #       excludeMetrics:
    #         - kube_replicaset_status_.*
    #         - kube_replicaset_created
    #         - kube_replicaset_metadata_generation
    #         - kube_replicaset_owner
    #         - kube_replicaset_spec_replicas
    #         - kube_pod_status_reason
    #         - node_namespace_pod_container:container_memory_cache
    #         - node_namespace_pod_container:container_memory_swap
    #         - kube_pod_container_status_restarts_total
    #         - kubelet_cgroup_manager_duration_seconds_bucket
    #         - kubelet_pod_start_duration_seconds_bucket
    #         - container_fs_.*
    #         - cluster:namespace:pod_.*
    #         - container_network_.*
    #   node-exporter:
    #     metricsTuning:
    #       dropMetricsForFilesystem:
    #         - tempfs # default
    #         - tmpfs
